{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e5ea1f-f00d-497d-9dbe-9b01b2b3d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf53ec2c-f661-4abe-945d-6d949417d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean_pool(hidden_states, labels):\n",
    "    \"\"\"\n",
    "    全局均值池化（所有有效token取平均）\n",
    "    \n",
    "    Args:\n",
    "        hidden_states: 模型最后一层隐藏状态 [batch_size, seq_len, hidden_dim]\n",
    "        labels: 每个token的标签 [batch_size, seq_len]（-100表示无效）\n",
    "        \n",
    "    Returns:\n",
    "        pooled_features: 池化后的特征 [batch_size, hidden_dim]\n",
    "    \"\"\"\n",
    "    # 创建有效掩码（排除-100），并转换为与hidden_states相同的数据类型\n",
    "    valid_mask = (labels != -100).unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "    valid_mask = valid_mask.to(hidden_states.dtype)  # 确保数据类型一致\n",
    "    \n",
    "    # 计算加权和（自动广播valid_mask到hidden_dim维度）\n",
    "    sum_hidden = torch.sum(hidden_states * valid_mask, dim=1)  # [batch_size, hidden_dim]\n",
    "    \n",
    "    # 计算有效token数量（转换为浮点型）\n",
    "    num_valid = torch.sum(valid_mask, dim=1)  # [batch_size, 1]\n",
    "    num_valid = torch.clamp(num_valid, min=1e-7)  # 防止除零\n",
    "    \n",
    "    # 均值池化（广播除法）\n",
    "    pooled_features = sum_hidden / num_valid\n",
    "    return pooled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebad7ce-ae03-4d3b-bf4a-459e1a006ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 100, 2])\n",
      "池化后的特征: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 示例 2\n",
    "batch_size = 3\n",
    "seq_len = 100\n",
    "hidden_dim = 2\n",
    "hidden_states = torch.randint(low=0, high=10, size=(batch_size, seq_len, hidden_dim))\n",
    "# 生成随机的 labels，部分值设为 -100 表示无效\n",
    "labels = torch.randint(low=-100, high=5, size=(batch_size, seq_len))\n",
    "# labels = torch.tensor([[1, 1, -100, 2], [3, -100, 3, 4], [1, 1, -100, -100]])\n",
    "\n",
    "pooled_features= global_mean_pool(hidden_states, labels)\n",
    "print(hidden_states.shape)\n",
    "print(\"池化后的特征:\", pooled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a738-54bc-45be-905b-4cdab6504c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7568cf8c-58d9-43d1-8482-d3f95639fe58",
   "metadata": {},
   "source": [
    "### 测试损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f910f84-0af0-41ec-bdf6-14da6dd13d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70faf5d7-b328-4d98-aa64-b3d78ae9d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_features\n",
      " tensor([[ 2.7103,  1.7868,  0.3986, -0.5020, -1.1758, -1.4855,  1.0214,  1.9834],\n",
      "        [-0.2004,  0.4443, -1.7188, -0.4812,  1.4300, -0.8460, -1.5075,  0.6973],\n",
      "        [ 1.1274,  0.1804, -0.4552, -0.3153, -0.5012, -1.4247,  0.4055,  0.4647],\n",
      "        [-0.4812, -0.9740,  1.4976, -0.0072, -0.4334, -0.4316, -0.8480, -1.2850]])\n",
      "nce_labels\n",
      " tensor([0, 0, 1, 1])\n",
      "pos_mask:\n",
      " tensor([[False,  True, False, False],\n",
      "        [ True, False, False, False],\n",
      "        [False, False, False,  True],\n",
      "        [False, False,  True, False]])\n",
      "neg_mask:\n",
      " tensor([[False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True, False, False]])\n",
      "改进后的损失值: 4.902640342712402\n"
     ]
    }
   ],
   "source": [
    "class FocalInfoNCE(nn.Module):\n",
    "    def __init__(self, m=0.5, tau=0.1, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.tau = tau\n",
    "        self.eps = eps  # 数值稳定性参数\n",
    "\n",
    "    def forward(self, emb_features, nce_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            emb_features (Tensor): 特征向量，(batch_size, feature_dim)\n",
    "            nce_labels (Tensor): 类别标签，(batch_size,)\n",
    "        Returns:\n",
    "            loss (Tensor): 标量损失值\n",
    "        \"\"\"\n",
    "        batch_size = emb_features.size(0)\n",
    "        device = emb_features.device\n",
    "\n",
    "        # 1. 特征归一化（余弦相似度）\n",
    "        emb_features = nn.functional.normalize(emb_features, p=2, dim=1)  # L2归一化\n",
    "        sim_matrix = torch.matmul(emb_features, emb_features.T)  # (b, b)\n",
    "\n",
    "        # 2. 构造正/负样本掩码\n",
    "        pos_mask = (nce_labels.unsqueeze(1) == nce_labels.unsqueeze(0)) & \\\n",
    "                  (~torch.eye(batch_size, dtype=torch.bool, device=device))\n",
    "        print(\"pos_mask:\\n\",pos_mask)\n",
    "        neg_mask = (nce_labels.unsqueeze(1) != nce_labels.unsqueeze(0))\n",
    "        print(\"neg_mask:\\n\",neg_mask)\n",
    "\n",
    "        # 3. 正样本得分（平均处理）\n",
    "        s_p = torch.sum(sim_matrix * pos_mask, dim=1) / (pos_mask.sum(dim=1) + self.eps)\n",
    "\n",
    "        # 4. 负样本调制项（仅保留负样本位置）\n",
    "        s_n_terms = sim_matrix.clone()  # 避免修改原始张量\n",
    "        s_n_terms = s_n_terms * neg_mask.float()  # 清零正样本位置\n",
    "        s_n_terms = s_n_terms * (s_n_terms + self.m) / self.tau  # 仅负样本参与计算\n",
    "\n",
    "        # 5. 数值稳定损失计算\n",
    "        max_val = torch.max((s_p** 2) / self.tau)  # 防止指数溢出\n",
    "        numerator = torch.exp((s_p** 2) / self.tau - max_val)\n",
    "        denominator = numerator + torch.sum(torch.exp(s_n_terms - max_val), dim=1)\n",
    "        loss = - (torch.log(numerator / (denominator + self.eps)) + max_val)  # 恢复偏移\n",
    "\n",
    "        return loss.mean().item()\n",
    "\n",
    "# 示例数据（归一化后）\n",
    "batch_size = 4\n",
    "feature_dim = 8\n",
    "emb_features = torch.randn(batch_size, feature_dim)\n",
    "nce_labels = torch.tensor([0, 0, 1, 1])\n",
    "print(\"emb_features\\n\",emb_features)\n",
    "print(\"nce_labels\\n\",nce_labels)\n",
    "# 初始化损失函数\n",
    "criterion = FocalInfoNCE(m=0.5, tau=0.1)\n",
    "\n",
    "# 计算损失\n",
    "loss = criterion(emb_features, nce_labels)\n",
    "print(\"改进后的损失值:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4dc48-3b24-483f-a466-206f05d9275d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0d5ea-8034-4593-b831-b3e4e112f4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf6fb7-7055-41db-9fcc-e88eca7e2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, tau=0.07, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # 正样本项的加权系数\n",
    "        self.tau = tau      # 温度参数\n",
    "        self.eps = eps      # 数值稳定性常数\n",
    "        # 确保参数合法性\n",
    "        assert self.alpha > 0, \"Alpha must be greater than 0\"\n",
    "        assert self.tau > 0, \"Tau must be greater than 0\"\n",
    "        assert self.eps > 0, \"Epsilon must be greater than 0\"\n",
    "\n",
    "    def forward(self, cos_sim, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cos_sim: (b, n) 输入的相似度矩阵，未经过温度缩放\n",
    "            labels: (b,) 每个样本的正样本位置索引\n",
    "        Returns:\n",
    "            loss: 计算得到的损失值，保留梯度信息\n",
    "        \"\"\"\n",
    "        device = cos_sim.device\n",
    "        b, n = cos_sim.shape\n",
    "\n",
    "        # 提取正样本分数并增强 (b,)\n",
    "        pos_scores = cos_sim.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
    "        enhanced_pos = self._enhance_pos(pos_scores)  # 正样本增强\n",
    "\n",
    "        # 调制负样本分数 (b, n)\n",
    "        mod_neg_scores = self._modulate_neg(cos_sim)\n",
    "        weighted_neg = self._weight_neg(cos_sim)  # 负样本加权\n",
    "        mod_neg_scores_weight = mod_neg_scores * weighted_neg  # 应用对样本进行加权\n",
    "\n",
    "        # 生成 mask 以排除正样本位置 (b, n)\n",
    "        mask = torch.zeros_like(mod_neg_scores_weight, dtype=torch.bool)\n",
    "        mask.scatter_(1, labels.unsqueeze(1), True)  # 正样本位置标记为True\n",
    "\n",
    "        # 将正样本位置分数设为-无穷，避免其参与负样本求和\n",
    "        mod_neg_scores_weight_masked = mod_neg_scores_weight.masked_fill(mask, -float('inf'))\n",
    "        \n",
    "        # 计算负样本的指数和 (b,)\n",
    "        sum_neg_logits = torch.logsumexp(mod_neg_scores_weight_masked, dim=1)\n",
    "        sum_neg_exp = sum_neg_logits.exp()\n",
    "\n",
    "        # 正样本加权调整 (b,)\n",
    "        weighted_pos = self._weight_pos(pos_scores)\n",
    "        adjusted_pos = enhanced_pos + weighted_pos\n",
    "\n",
    "        # 构造分母项\n",
    "        pos_exp_term = weighted_pos\n",
    "        denominator = pos_exp_term + sum_neg_exp + self.eps\n",
    "\n",
    "        # 计算最终损失 (log(denominator) - adjusted_pos) 的均值\n",
    "        loss = (torch.log(denominator) - adjusted_pos).mean().item()\n",
    "\n",
    "        return loss\n",
    "    # 定义各调制函数\n",
    "\n",
    "    def _enhance_pos(self, pos_scores):\n",
    "        \"\"\"\n",
    "        正样本增强函数\n",
    "        Args:\n",
    "            pos_scores: (b,) 正样本分数\n",
    "        Returns:\n",
    "            enhanced_pos: (b,) 增强后的正样本分数\n",
    "        \"\"\"\n",
    "        enhanced_pos = pos_scores.clone().to(pos_scores.device)  # 深拷贝，避免原地操作\n",
    "        enhanced_pos = enhanced_pos/self.tau\n",
    "        return enhanced_pos\n",
    "    \n",
    "    def _modulate_neg(self, neg_scores):\n",
    "        \"\"\"\n",
    "        负样本调制函数\n",
    "        Args:\n",
    "            neg_scores: (b, n) 负样本分数\n",
    "        Returns:\n",
    "            modulated_neg: (b, n) 调制后的负样本分数\n",
    "        \"\"\"\n",
    "        modulated_neg = neg_scores.clone().to(neg_scores.device)  # 深拷贝，避免原地操作\n",
    "        modulated_neg = modulated_neg/self.tau\n",
    "        return modulated_neg\n",
    "\n",
    "    def _weight_pos(self, pos_scores):\n",
    "        \"\"\"\n",
    "        正样本加权函数\n",
    "        Args:\n",
    "            pos_scores: (b,) 正样本分数\n",
    "        Returns:\n",
    "            weighted_pos: (b,) 加权后的正样本分数\n",
    "        \"\"\"\n",
    "        # weighted_pos = pos_scores.clone()\n",
    "        weighted_pos = torch.full_like(pos_scores, self.alpha).to(pos_scores.device)\n",
    "        return weighted_pos\n",
    "    \n",
    "    def _weight_neg(self, neg_scores):\n",
    "        \"\"\"\n",
    "        负样本加权函数\n",
    "        Args:\n",
    "            neg_scores: (b, n) 负样本分数\n",
    "        Returns:\n",
    "            weighted_neg: (b, n) 加权后的负样本分数\n",
    "        \"\"\"\n",
    "        # weighted_neg = neg_scores.clone()\n",
    "        weighted_neg = torch.full_like(neg_scores, self.alpha).to(neg_scores.device)\n",
    "        return weighted_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a0c26-5eeb-48d2-ac4d-9fcfb893e263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4508d-c16a-4d61-8bf8-b08bb1869ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(3.8.8)",
   "language": "python",
   "name": "env-3.8.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
